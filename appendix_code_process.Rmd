---
title: "Appendix"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)

library(tidyverse)
library(faraway)
library(HH)
library(leaps)
library(caret)
library('glmnet')                         # for glmnet()
library(boot)                          # For cv.glm()
library(MPV)

```


## Data exploration and cleaning


```{r}
# import data
cancer = read_csv('./data/Cancer_Registry.csv') %>%
  janitor::clean_names() %>%
  mutate(state = str_replace(str_extract(geography, ', .*'), ', ', ''), # group counties by state
         state = recode(state, "District of Columbia" = "Maryland"),
         log_ann_count = log(avg_ann_count), # log transformations
         log_deaths_yr = log(avg_deaths_per_year),
         log_pop = log(pop_est2015),
         pct_minority = 100 - pct_white,
         pct_college = pct_bach_deg25_over + pct_bach_deg18_24, # aggregate for percent of college graduates
         pct_healthinsurance = pct_private_coverage + pct_public_coverage) # aggregate for percent with insurance


# selection of variables based on our exploration 
cancer_varselect = cancer %>%
  dplyr::select(target_death_rate,
                log_ann_count,
                incidence_rate,
                poverty_percent,
                study_per_cap,
                median_age_male,
                avg_household_size,
                percent_married,
                pct_college,
                pct_unemployed16_over,
                pct_minority,
                pct_healthinsurance,
                state)


cancer %>%
  dplyr::select(target_death_rate,
                log_ann_count,
                log_deaths_yr,
                log_pop) %>%
  cor

```


```{r}
# cancer %>%
#   group_by(state) %>%
#   ggplot(aes(y = target_death_rate, x = state)) + 
#   geom_violin() + 
#   coord_flip()
# 
# cancer %>%
#   group_by(region) %>%
#   ggplot(aes(y = target_death_rate, x = region)) + 
#   geom_violin()
# 
# cancer %>%
#   ggplot(aes(y = pct_minority, x = state)) +
#   geom_violin() +
#   coord_flip()
```


We first examined variables for any skewness, and then tested associations between covariates to identify potential sources of collinearity. We found that several sets of variables were correlated. For those groups of correlated covariates, we generally chose to include the single covariate that was most highly associated with the outcome, cancer mortality rate.

We saw that median age was highly skewed, to the point that we think there is some sort of data error. Keep this in mind for later; for now we remove from the list of selected parameters. We opt instead to use the median age in males as a proxy, since the distribution (discarding the outliers in median age) is comparable to median age overall and median age in females. It's also interesting to note that median age between males and females are highly correlated eith each other, but not much correlated with target death rate. In fact, median age in males is negatively correlated with death rate, while median age for females is positively correlated.

We looked again at the variables for the percent of the population of a certain race and found that log transformation was bimodal. It might make sense to make this binary (i.e. >5% of a certain race or not). In the end, we chose to make a single variable measuring the percent of the population that is non-white (considered minority). This variable was skewed, but we did not perform a transformation for the sake of interpretability.

We combined several variables to create aggregate measures. We initially thought to group counties by region (Northeast, South, Midwest, West), but found that state-level groupings provided better fit and predictive capability. We designated the District of Columbia as being part of Maryland, since it had a single observation. We also created single measures for the percent of the population with a bachelor's degree and percent of the population with health insurance.

Median income and the percent of the population in poverty are correlated with each other as well as the percent of the population with a college degree. Percent in poverty had a slightly higher association with the death rate, and a slightly lower correlation with education (as measured), so we opted to include it over median income. 


```{r, echo = FALSE, include = TRUE}
descrip_list = cancer_varselect %>%
  dplyr::select(-state) %>%
  skimr::skim_to_list()

descrip_list[[1]] %>% 
  mutate(variable = recode(variable, avg_household_size = 'Avg household size',
                           incidence_rate = 'Cancer incidence',
                           log_ann_count = 'Percent change in number of new cases',
                           median_age_male = 'Median age among men',
                           pct_college = 'Pop. percentage with college degree',
                           pct_healthinsurance = 'Pop. percentage with insurance',
                           pct_minority = 'Pop. percentage non-white',
                           pct_unemployed16_over = 'Unemployment rate',
                           percent_married = 'Pop. percentage married',
                           poverty_percent = 'Pop. percentage in poverty',
                           study_per_cap = 'Avg number of clinical studies',
                           target_death_rate = 'Cancer mortality rate (per 100,000)')) %>%
  dplyr::select(Measure = variable, 
                Min = p0,
                `1st Q` = p25,
                Mean = mean,
                Median = p50,
                `3rd Q` = p75,
                Max = p100,
                `Std Dev` = sd) %>% 
  knitr::kable(digits = 3)
```


## Model selection

### Stepwise

```{r}
# Stepwise 
step.fit = step(lm(target_death_rate ~ ., data = cancer_varselect))
summary(step.fit)

step.fit.bic = step(lm(target_death_rate ~ ., data = cancer_varselect), k = log(3047))
summary(step.fit.bic)
```


### Lasso Model Selection / checking our stepwise coefficients

```{r}
## Lasso on selected variables
set.seed(1)
Y <- cancer_varselect$target_death_rate
X <- model.matrix( ~ . , data = cancer_varselect[,-1])
train <- sample(1:nrow(X), nrow(X)/2)
grid <- 10^seq(5, -2, length = 100)

# lasso1 <- glmnet(X[train ,],Y[train], alpha = 1, lambda = grid)
cv.out <- cv.glmnet(X[train,],Y[train]) # all possible lambda values

par(mfrow = c(1, 1))
plot(cv.out) # CV process

coef(glmnet(X, Y, alpha = 1, lambda = cv.out$lambda.min)) # fitting with chosen lambda
(glmnet(X, Y, alpha = 1, lambda = cv.out$lambda.min))$dev.ratio
```


We used a combination of stepwise selection (using AIC) and Lasso to choose our final model. When we tested our original selected variables under both processes, we find the same parameters are downweighted/removed.

We also tried fitting Lasso on the full original dataset (with our transformed/grouped variables) and found that many of the covariates appeared meaningful. However, this model seemed to overfit the data, especially since it chose to include some predictors with known correlation (e.g. median income and the percent of the population in poverty), suggesting presence of multicollinearity.

We performed stepwise regression using both AIC and BIC criterion, and found that using BIC resulted in several fewer variables being selected. But due to known associations between the eliminated variables and cancer mortality, we choose to include them in our model. For example, stepwise regression based on both criteria eliminated the percent of the population with health insurance as a predictor of cancer mortality per capita. However, we suspect this may be a practically meaningful covariate, since it has been shown that those with health insurance tend to have improved cancer outcomes over those without health insurance. This was done on an individual level (https://www.ncbi.nlm.nih.gov/pubmed/29192307) and by relating individual insurance coverage with communities (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5360496/). 

Our final model uses cancer incidence, percent change in the number of new diagnoses from year to year, percent of the population in poverty, median age, percent of the population that is married, percent of the population with a college degree, percent of the population that is non-white, percent unemployment, and the percent of the population with health insurance to predict the average cancer death rate per 100,000 across states.

```{r}
# Decided model based on stepwise and decision about meaningful covariates
final.model = lm(target_death_rate ~ incidence_rate + poverty_percent + 
    median_age_male + percent_married + pct_college + pct_unemployed16_over + pct_minority +
    pct_healthinsurance + state, 
    data = cancer_varselect)
summary(final.model)
```




## Model diagnostics

Testing assumptions for final model:

```{r, echo = FALSE, include = TRUE}
par(mfrow = c(2, 2))
plot(final.model)
```

We see that there are long tails on both sides of the distribution. This may be due to outliers at either extreme, so next we examine presence of outliers and potentially influential points.

```{r}
stu_res <- rstandard(final.model)
outliers_y <- stu_res[abs(stu_res) > 2.5] # there are 71 outliers

# None of the points lie beyond a Cook's distane of 0.5, but point 116, 124, and 282 are noted

# Examine results with and without observations 5 and 28 that have very high survivals (>2000)
cancer_noinfluential = cancer_varselect[-c(116, 124, 282), ] # all rows except potential influencers

fit_noinfluential <- lm(target_death_rate ~ incidence_rate + poverty_percent + 
    median_age_male + percent_married + pct_college + pct_unemployed16_over + pct_minority +
    pct_healthinsurance + state, 
    data = cancer_noinfluential)


summary(fit_noinfluential)
par(mfrow = c(2, 2))
plot(fit_noinfluential)
```

Skewness still exists without these influential points, but the model's R2 and Adj R2 both improve marginally. As a result, we opt to keep these observations in our model.







## Model validation

K-fold CV

```{r, echo = FALSE, include = TRUE}
kfold_cv = lapply(1:10, function(i){
  # create 10-fold training datasets
  data_train <- trainControl(method = "cv", number = 10)

  # Fit the model used above
  model_caret <- train((target_death_rate ~ incidence_rate + poverty_percent + 
    median_age_male + percent_married + pct_college + pct_unemployed16_over + pct_minority + pct_healthinsurance +
    state),
                     data = cancer_varselect,
                     trControl = data_train,
                     method = 'lm',
                     na.action = na.pass)
  
  #return(list(model_caret$results, model_caret$resample))
  return(model_caret$results)
})

do.call("rbind", kfold_cv) %>%
  dplyr::select(RMSE, RMSESD) %>% # summarise(mse = mean(RMSE))
  mutate(MSE = RMSE^2,
         std.error = RMSESD / 9) %>%
  dplyr::select(1, 3, 2, 4) %>% summarise(MSE = mean(MSE),
                                          RMSE = mean(RMSE),
                                          SE = mean(std.error)) %>%
  knitr::kable()
```



Criterion comparison

```{r, echo = FALSE, include = TRUE}
newsummary <- function(model)
{
    list('coefs'    = round(t(summary(model)$coef[, 1:2]), 4),
         'criteria' = cbind('SSE'   = anova(model)["Residuals", "Sum Sq"],
                            'PRESS' = PRESS(model),
                            'RMSE'   = sqrt(anova(model)["Residuals", "Mean Sq"]),
                            'Adjusted Rsq'   = summary(model)$adj.r.squared))
}

newsummary(lm(target_death_rate ~ incidence_rate + poverty_percent + 
    median_age_male + percent_married + pct_college + pct_unemployed16_over + pct_minority +
    pct_healthinsurance + state, 
    data = cancer_varselect))$criteria %>%
  knitr::kable()

```

Our 10-fold cross validation shows root MSE of ~18.7. Performing leave-one-out (N-fold) cross validation gives a comparable value. We also examine other criteria (SSE, R-squared, and PRESS). 



## Commentary


Our model does a decent job of predicting cancer mortality rates, despite challenges. Skewness in the data is a hurdle that we cannot seem to overcome using linear methods; non-linear alternatives may better handle this issue. 

That being said, our final model is not the one with the lowest MSE, but it accounts for over 50% of the variability in the outcome and uses what we believe is the fewest number of significant and/or practically meaningful covariates. 
